{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marta\\anaconda3\\envs\\iannwtf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CheXNet applied to chest X-ray images classifying pneumonia vs non-pneumonia.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow.python.keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from loss import WeightedCrossEntropyBinaryLoss\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import prepare_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# input_path = '../input/chest_xray/chest_xray/'\n",
    "input_path = 'C:/Users/marta/OneDrive/Desktop/Osnabruck/ImplementingANNswithTensorFlow/FinalProject/chest_xray/'\n",
    "\n",
    "# Checkpoint file path\n",
    "checkpoint_filepath = 'C:/Users/marta/OneDrive/Desktop/Osnabruck/ImplementingANNswithTensorFlow/FinalProject/Checkpoint/weights.hdf5' \n",
    "\n",
    "# Train data path\n",
    "train_data_path = input_path+'train'\n",
    "\n",
    "# Val data path\n",
    "val_data_path = input_path+'test'\n",
    "\n",
    "# Hyperparameters\n",
    "img_dims = 224\n",
    "n_epochs = 10\n",
    "batch_size = 16 # since it's a binary classification task\n",
    "val_batch_size = 64\n",
    "output_size = 1\n",
    "\n",
    "# Getting the data\n",
    "train_gen, test_gen, test_data, test_labels = prepare_data.prepare_data(img_dims, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXNet(tf.keras.Model):\n",
    "  \"\"\"\n",
    "  The model using modified DenseNet121.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__ (self):\n",
    "    \"\"\"\n",
    "    The constructor initiates the layers and their activation functions....\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    # Following will be set by get_data_stats() based on the dataset\n",
    "    self.zero_weight = None\n",
    "    self.one_weight = None\n",
    "    self.train_steps = None\n",
    "    self.val_steps = None\n",
    "\n",
    "    # get_model() will initialize this to DenseNet121 model\n",
    "    self.model = None\n",
    "  \n",
    "  def get_data_stats(self, train_data_path, val_data_path):\n",
    "    \"\"\"\n",
    "    Computes normal Vs Pneumonia class distribution.\n",
    "    :param train_data_path: path to training data. Samples os each class should be stored in separate folders\n",
    "    :param val_data_path: path to validation data. Samples os each class should be stored in separate folders\n",
    "    \"\"\"\n",
    "\n",
    "    # Count images in each class\n",
    "    n_normal = len(os.listdir(train_data_path + '/NORMAL'))\n",
    "    n_infect = len(os.listdir(train_data_path + '/PNEUMONIA'))\n",
    "\n",
    "    # compute class distribution\n",
    "    self.w_class1 = float(n_normal)/(n_normal+n_infect)\n",
    "    self.w_class0 = float(n_infect)/(n_normal+n_infect)\n",
    "\n",
    "    # For convenience at train time, compute number of steps required to complete an epoch\n",
    "    n_normal_val = len(os.listdir(val_data_path + '/NORMAL'))\n",
    "    n_infect_val = len(os.listdir(val_data_path + '/PNEUMONIA'))\n",
    "\n",
    "    self.train_steps = ((n_normal+n_infect) // batch_size) + 1\n",
    "    self.val_steps = ((n_normal_val+n_infect_val) // val_batch_size) + 1  \n",
    "\n",
    "\n",
    "  def get_model(self):\n",
    "    # DenseNet121 expects number of channels to be 3\n",
    "    input = Input(shape=(img_dims, img_dims, 3))\n",
    "\n",
    "    # using pretrained DenseNet121 as the foundation of the model\n",
    "    base_model = tf.keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_tensor=input,\n",
    "                                                            input_shape=(img_dims, img_dims, 3))\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.layers[-1].output)\n",
    "    x = tf.keras.layers.Dense(output_size, activation=tf.nn.sigmoid)\n",
    "\n",
    "    self.model = Model()\n",
    "\n",
    "    # Using weighted binary loss has been suggested in the paper\n",
    "    loss = WeightedCrossEntropyBinaryLoss(self.zero_weight, self.one_weight)\n",
    "\n",
    "    # Compile the model\n",
    "    self.model.compile(optimizer=tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999),\n",
    "                       loss=loss.weighted_binary_crossentropy, metrics=['accuracy'])\n",
    "    \n",
    "    return self.model\n",
    "\n",
    "# Instantiate the CheXNet model\n",
    "chexnet = CheXNet()\n",
    "\n",
    "# Compute normal Vs Pneumonia class distribution\n",
    "chexnet.get_data_stats(train_data_path, val_data_path)\n",
    "\n",
    "# Create and compile the DenseNet121 model\n",
    "model = chexnet.get_model()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.DirectoryIterator object at 0x000001AF97510850>\n"
     ]
    }
   ],
   "source": [
    "print(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marta\\OneDrive\\Desktop\\Osnabruck\\IANNwTFfinalProject\\draft.ipynb Cell 4\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marta/OneDrive/Desktop/Osnabruck/IANNwTFfinalProject/draft.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# #Fitting the model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marta/OneDrive/Desktop/Osnabruck/IANNwTFfinalProject/draft.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit_generator(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marta/OneDrive/Desktop/Osnabruck/IANNwTFfinalProject/draft.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_gen, epochs\u001b[39m=\u001b[39mn_epochs, validation_data\u001b[39m=\u001b[39m\u001b[39mtuple\u001b[39;49m(test_gen), callbacks\u001b[39m=\u001b[39m[reduce_lr, model_checkpoint],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marta/OneDrive/Desktop/Osnabruck/IANNwTFfinalProject/draft.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39mchexnet\u001b[39m.\u001b[39mtrain_steps, validation_steps\u001b[39m=\u001b[39mchexnet\u001b[39m.\u001b[39mval_steps)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marta/OneDrive/Desktop/Osnabruck/IANNwTFfinalProject/draft.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Load the model with the lowest validation loss\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marta/OneDrive/Desktop/Osnabruck/IANNwTFfinalProject/draft.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mload_weights(checkpoint_filepath)\n",
      "File \u001b[1;32mc:\\Users\\marta\\anaconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\preprocessing\\image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marta\\anaconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\preprocessing\\image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     index_array \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_generator)\n\u001b[0;32m    166\u001b[0m \u001b[39m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batches_of_transformed_samples(index_array)\n",
      "File \u001b[1;32mc:\\Users\\marta\\anaconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\preprocessing\\image.py:370\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    368\u001b[0m filepaths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepaths\n\u001b[0;32m    369\u001b[0m \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(index_array):\n\u001b[1;32m--> 370\u001b[0m     img \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39;49mload_img(\n\u001b[0;32m    371\u001b[0m         filepaths[j],\n\u001b[0;32m    372\u001b[0m         color_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolor_mode,\n\u001b[0;32m    373\u001b[0m         target_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_size,\n\u001b[0;32m    374\u001b[0m         interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation,\n\u001b[0;32m    375\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m    376\u001b[0m     )\n\u001b[0;32m    377\u001b[0m     x \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39mimg_to_array(img, data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format)\n\u001b[0;32m    378\u001b[0m     \u001b[39m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[39m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marta\\anaconda3\\envs\\iannwtf\\lib\\site-packages\\keras\\utils\\image_utils.py:440\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m color_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mmode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 440\u001b[0m         img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcolor_mode must be \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgba\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marta\\anaconda3\\envs\\iannwtf\\lib\\site-packages\\PIL\\Image.py:921\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[0;32m    874\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[0;32m    875\u001b[0m ):\n\u001b[0;32m    876\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 921\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    923\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    924\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    925\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marta\\anaconda3\\envs\\iannwtf\\lib\\site-packages\\PIL\\ImageFile.py:260\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m         )\n\u001b[0;32m    259\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 260\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    262\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #Fitting the model\n",
    "history = model.fit_generator(\n",
    "    train_gen, epochs=n_epochs, validation_data=tuple(test_gen), callbacks=[reduce_lr, model_checkpoint],\n",
    "    steps_per_epoch=chexnet.train_steps, validation_steps=chexnet.val_steps)\n",
    "\n",
    "\n",
    "# Load the model with the lowest validation loss\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
